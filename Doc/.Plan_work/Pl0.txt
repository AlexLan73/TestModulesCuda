
Техническое задание: Разработка библиотеки примитивов ЦОС на CUDA
Цель проекта: Создание высокопроизводительного набора тестовых модулей и примитивов для цифровой обработки сигналов 
   (DSP) на архитектуре CUDA с расширенными возможностями профилирования.
1. Функциональные модули (CUDA Kernels)
  Реализация кастомных ядер (kernels) с упором на максимальную утилизацию GPU (Memory Bandwidth Bound / Compute Bound оптимизации).
  1.1. Генератор псевдослучайных чисел (PRNG)
    Описание: Управляемый генератор с поддержкой детерминированного поведения (seedable).
    Требования: Поддержка заданных законов распределения (равномерное, нормальное/Гауссово).
    Реализация алгоритма без использования внешних тяжеловесных библиотек (например, cuRAND), 
      если требуется минимизация оверхеда, либо обертка над stateful-генераторами (XORWOW, Philox).

  1.2. Оптимизированный битовый сдвиг
    Описание: Параллельный арифметический/логический сдвиг массива данных.
    Требования: Сдвиг на величину n  (эквивалент деления на двойки).
    Векторизация доступа к памяти int4.

  1.3. Генерация гармонических сигналов (Matrix Sin)
    Описание: Формирование матрицы значений синусоидальных сигналов.
    Требования: Поддержка вычисления по формуле A⋅sin(ωt + ϕ).
    Обсудить Возможность генерации многоканальных данных (фазовая матрица).
    Требования: Параметрическое задание смещения (offset) и длительности.
    Обработка граничных условий при выходе сигнала за пределы буфера.

  1.5. Фильтр нижних частот (ФНЧ / LPF)
    Описание: Реализация цифрового фильтра нижних частот.
    Требования: Параллельная реализация ( IIR структура).
    Оптимизация использования Shared Memory для кэширования "окна" фильтра (halo-область).

  1.6. Оконная фильтрация (Окно Кайзера)
    Описание: Генерация и применение весового окна Кайзера-Бесселя.
    Высокоэффективное поэлементное умножение (FMA - Fused Multiply-Add).

  1.7. Формирование выходного вектора 
  
2. Инструментарий профилирования и отладки
  Разработка подсистемы метрик для детального анализа производительности гетерогенной системы (CPU + GPU).

  2.1. Двухуровневое профилирование (Hybrid Profiling)  Комплексный сбор метрик таймингов:
  2.2. Host-side (CPU):
    Измерение времени на уровне вызова API-функций (Latency).
    Фиксация накладных расходов (overhead) на запуск ядер (kernel launch latency) и передачу данных (H2D/D2H).
  2.3. Device-side (GPU):
    Использование cudaEvent для точного измерения чистого времени исполнения (Execution Time) 
      каждого блока/ядра без учета задержек CPU.
    Цель: Выявление "бутылочных горлышек" (bottlenecks) и дисбаланса нагрузки между хостом и устройством.

  2.4. Система сквозного логирования (Trace Logging)
    Описание: Внедрение легковесного механизма логирования таймингов.
    Требования: Условная компиляция макросами (например, #ifdef DEBUG_PROFILING) для отключения в релизной сборке (Zero-overhead in Release).
    Сбор контрольных точек (timestamps) по всему тракту обработки данных для построения временной диаграммы выполнения.     
   
Модули:   
Описание классов и структур
  1. Прописать интерфейсы 
  2. Создавать модуль под как отдельный lib

Преречень работ: 
Технический план реализации: GPU-акселерированный конвейер ЦОС
Общие архитектурные положения:
Платформа вычислений: Полный перенос вычислительной нагрузки на GPU (Device).
Модель памяти: Используется единый непрерывный буфер данных типа int32.
Объем данных: Длина строба фиксирована — 3.5 млн точек (approx. 13.35 MB) - максимальный вектор.
Оптимизация: Все операции доступа к глобальной памяти векторизуются через тип int4 (128-битные транзакции).

Этап 1. Генерация псевдослучайных последовательностей (PRNG)
Разработка и верификация алгоритма генерации данных.
  1.1. Реализация PRNG на GPU (Device)
    1.1.1. Инициализация: Определение таблицы полиномов и коэффициентов для алгоритма генерации (например, LFSR или PCG).
    1.1.2. Генерация: Разработка CUDA-кернела для формирования вектора заданной длины (3.5 млн точек) на основе выбранного алгоритма.
  1.2. Реализация эталонного PRNG на CPU (Host)
    Дублирование алгоритма на C++ для выполнения на центральном процессоре с целью последующей валидации.
  1.3. Валидация данных
    Побитовое сравнение результатов GPU и CPU (memcmp) для подтверждения идентичности генерируемых последовательностей.

Этап 2. Оптимизированный битовый сдвиг
  Реализация высокопроизводительной операции сдвига данных.
  2.1. Векторизованный кернел (int4)
    Реализация кастомного CUDA-кернела, использующего reinterpret_cast<int4*> для загрузки 4-х элементов int32 в регистры за одну транзакцию памяти.
    Выполнение операции побитового сдвига (>> 16) над векторными типами.
  2.2. Инкапсуляция логики
    Оформление логики сдвига в виде отдельной __device__ функции или вызываемого модуля (callable) для повторного использования в других кернелах.

Этап 3. Формирование опорных сигналов (LFM/Sin)
  Подготовка данных для поэлементного умножения и модуляции.
  3.1. Генерация глобальной синусоиды
    Формирование единого синусоидального сигнала на всю длину вектора данных.
  3.2. Генерация фазозависимых сигналов (Multi-channel)
    Формирование сигналов с уникальной фазой для каждого канала/луча.
  3.3. Табличный метод (LUT) vs Pre-computed
    Реализация генерации через sin(w0 + phase).
    Приоритетный метод: Предварительный расчет полного буфера значений (жертвуем памятью ради упрощения вычислений в основном цикле обработки).
  3.4. Управление сдвигом
    Внедрение переменной для динамического сдвига фазы/позиции сигнала на заданное число отсчетов.
  3.5. Валидация
    Проверка спектральных характеристик и корректности фазовых сдвигов.

Этап 4. Управление интенсивностью (Intensity Scaling)
  Применение амплитудных коэффициентов к сигналу с использованием векторных инструкций.
  4.1. Арифметические операции с оптимизацией int4
    4.1.1. Скалярное умножение:
      Загрузка данных через int4.
      Умножение 4-х компонент вектора на единый скалярный коэффициент.
      Применение битового сдвига (нормализация) непосредственно в регистрах.
      Выгрузка результата.
  4.1.2. Векторное умножение (профиль интенсивности):
  Адаптация коэффициента фона (kFon)
  Вариант А (Uniform): Использование единого скаляра kFon для всего сигнала.
  Вариант Б (Beam-specific): Передача массива коэффициентов, где каждый луч/канал выбирает свой уровень шума при обработке.

Этап 5. Формирование помеха/сигнал (делать после Этап 1)
  5.1 Один принцип отличие вызов ФНЧ или Фильтр Кайзера с возможностью его обхода Кайзера, 
  признак tipsig=0 => ФНЧ,  tipsig>1 Кайзер & is_kazer=true.


Этап 6. Запуск потоков на GPU для ускорения расчетов, плтоки и примерная их последовательность
  6.1 Формирование сигналов (вместе помеха/сигнал)
  6.2 Наверно линейки sin по каналам на длинну сигнала
  6.3 Intens - если нужно формируем на все лучи разный интенсив
  6.4 Генерация шума.
  6.5 amplAfr - если нужно формируем на все лучи разный амплитудой
  6.6 Ожидаем завершение потоков п 6.1, 6.2 (помеха/сигнал и sin)
  6.7 Умножение sin на сигнал сдвиг
  6.8 Ожидаем завершение потоков п 6.3 (интенсив)
  6.9 Умножение и сдвиг
  6.10 Ожидаем завершение потоков п 6.4 (шум)
  6.11 Сложение!!!! пока не понятно 1) по лучас сигнал + шум или 2) все вместе сигналы + все шумы на точку???? потом сдвиг
  6.12 Ожидаем завершение потоков п 6.5 (amplAfr)
  6.13 Умножение и сдвиг
  6.14 Преобразовать в выходной вектор [ray0X[0], ]






-хх не понятно в Сумма по K+шум

и загрузить на GPU  